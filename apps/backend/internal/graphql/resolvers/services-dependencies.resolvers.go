package resolver

// This file will be automatically regenerated based on the schema, any resolver
// implementations
// will be copied through when generating and any unknown code will be moved to the end.
// Code generated by github.com/99designs/gqlgen version v0.17.86

import (
	graphql1 "backend/generated/graphql"
	"context"
	"fmt"
)

// AddDependency is the resolver for the addDependency field.
func (r *mutationResolver) AddDependency(ctx context.Context, input graphql1.AddDependencyInput) (*graphql1.ServiceDependency, error) {
	panic(fmt.Errorf("not implemented: AddDependency - addDependency"))
}

// RemoveDependency is the resolver for the removeDependency field.
func (r *mutationResolver) RemoveDependency(ctx context.Context, input graphql1.RemoveDependencyInput) (bool, error) {
	panic(fmt.Errorf("not implemented: RemoveDependency - removeDependency"))
}

// TriggerBootSequence is the resolver for the triggerBootSequence field.
func (r *mutationResolver) TriggerBootSequence(ctx context.Context) (bool, error) {
	panic(fmt.Errorf("not implemented: TriggerBootSequence - triggerBootSequence"))
}

// SetResourceLimits is the resolver for the setResourceLimits mutation field.
// Applies cgroups v2 memory limits to a running service instance.
func (r *mutationResolver) SetResourceLimits(ctx context.Context, input graphql1.SetResourceLimitsInput) (*graphql1.ResourceLimitsPayload, error) {
	r.log.Infow("SetResourceLimits mutation called",
		"routerID", input.RouterID,
		"instanceID", input.InstanceID,
		"memoryMB", input.MemoryMb)

	// Check if InstanceManager is available
	if r.InstanceManager == nil {
		return &model.ResourceLimitsPayload{
			Success:        false,
			ResourceLimits: nil,
			Errors: []*model.MutationError{{
				Code:    "SERVICE_UNAVAILABLE",
				Message: "Instance manager service is not available",
			}},
		}, nil
	}

	// Check if ResourceLimiter is available
	resourceLimiter := r.InstanceManager.ResourceLimiter()
	if resourceLimiter == nil {
		return &model.ResourceLimitsPayload{
			Success:        false,
			ResourceLimits: nil,
			Errors: []*model.MutationError{{
				Code:    "SERVICE_UNAVAILABLE",
				Message: "Resource limiter service is not available",
			}},
		}, nil
	}

	// Load the service instance from database
	instance, err := r.db.ServiceInstance.Query().
		Where(serviceinstance.IDEQ(input.InstanceID)).
		Where(serviceinstance.RouterIDEQ(input.RouterID)).
		Only(ctx)
	if err != nil {
		if ent.IsNotFound(err) {
			return &model.ResourceLimitsPayload{
				Success:        false,
				ResourceLimits: nil,
				Errors: []*model.MutationError{{
					Code:    "NOT_FOUND",
					Message: fmt.Sprintf("Service instance not found: %s", input.InstanceID),
				}},
			}, nil
		}
		r.log.Errorw("failed to query service instance",
			"error", err,
			"instanceID", input.InstanceID)
		return &model.ResourceLimitsPayload{
			Success:        false,
			ResourceLimits: nil,
			Errors: []*model.MutationError{{
				Code:    "DATABASE_ERROR",
				Message: fmt.Sprintf("Failed to query service instance: %v", err),
			}},
		}, nil
	}

	// Check if instance is running (would need PID to apply limits)
	// For MVP, we'll assume we can get the PID from the instance manager
	// In production, this would be stored in the database or tracked by InstanceManager
	pid := 0 // Placeholder - would come from instance manager's process tracker

	// Validate memory limit (minimum 16MB)
	if input.MemoryMb < 16 {
		return &model.ResourceLimitsPayload{
			Success:        false,
			ResourceLimits: nil,
			Errors: []*model.MutationError{{
				Code:    "INVALID_INPUT",
				Message: fmt.Sprintf("Memory limit %dMB is below minimum 16MB", input.MemoryMb),
				Field:   ptrString("memoryMB"),
			}},
		}, nil
	}

	// Apply memory limit via ResourceLimiter
	err = resourceLimiter.ApplyMemoryLimit(ctx, pid, input.MemoryMb, instance.ID, instance.FeatureID)
	if err != nil {
		r.log.Errorw("failed to apply memory limit",
			"error", err,
			"instanceID", input.InstanceID,
			"memoryMB", input.MemoryMb)
		return &model.ResourceLimitsPayload{
			Success:        false,
			ResourceLimits: nil,
			Errors: []*model.MutationError{{
				Code:    "LIMIT_APPLICATION_FAILED",
				Message: fmt.Sprintf("Failed to apply memory limit: %v", err),
			}},
		}, nil
	}

	// Return success with updated resource limits
	resourceLimits := &model.ResourceLimits{
		MemoryMb:   input.MemoryMb,
		CPUPercent: nil,
		Applied:    resourceLimiter.IsCgroupsEnabled(),
	}

	r.log.Infow("resource limits applied successfully",
		"instanceID", input.InstanceID,
		"memoryMB", input.MemoryMb,
		"cgroupsEnabled", resourceLimits.Applied)

	return &model.ResourceLimitsPayload{
		Success:        true,
		ResourceLimits: resourceLimits,
		Errors:         []*model.MutationError{},
	}, nil
}

// ServiceDependencies is the resolver for the serviceDependencies field.
func (r *queryResolver) ServiceDependencies(ctx context.Context, instanceID string) ([]*graphql1.ServiceDependency, error) {
	panic(fmt.Errorf("not implemented: ServiceDependencies - serviceDependencies"))
}

// ServiceDependents is the resolver for the serviceDependents field.
func (r *queryResolver) ServiceDependents(ctx context.Context, instanceID string) ([]*graphql1.ServiceDependency, error) {
	panic(fmt.Errorf("not implemented: ServiceDependents - serviceDependents"))
}

// DependencyGraph is the resolver for the dependencyGraph field.
func (r *queryResolver) DependencyGraph(ctx context.Context, routerID string) (*graphql1.DependencyGraph, error) {
	panic(fmt.Errorf("not implemented: DependencyGraph - dependencyGraph"))
}

// BootSequenceProgress is the resolver for the bootSequenceProgress field.
func (r *queryResolver) BootSequenceProgress(ctx context.Context) (*graphql1.BootSequenceProgress, error) {
	panic(fmt.Errorf("not implemented: BootSequenceProgress - bootSequenceProgress"))
}

// !!! WARNING !!!
// The code below was going to be deleted when updating resolvers. It has been copied here so you have
// one last chance to move it out of harms way if you want. There are two reasons this happens:
//  - When renaming or deleting a resolver the old code will be put in here. You can safely delete
//    it when you're done.
//  - You have helper methods in this file. Move them out to keep these resolver files clean.
/*
	func (r *mutationResolver) SetResourceLimits(ctx context.Context, input graphql1.SetResourceLimitsInput) (*graphql1.ResourceLimitsPayload, error) {
	r.log.Infow("SetResourceLimits mutation called",
		"routerID", input.RouterID,
		"instanceID", input.InstanceID,
		"memoryMB", input.MemoryMb)

	// Check if InstanceManager is available
	if r.InstanceManager == nil {
		return &model.ResourceLimitsPayload{
			Success:        false,
			ResourceLimits: nil,
			Errors: []*model.MutationError{{
				Code:    "SERVICE_UNAVAILABLE",
				Message: "Instance manager service is not available",
			}},
		}, nil
	}

	// Check if ResourceLimiter is available
	resourceLimiter := r.InstanceManager.ResourceLimiter()
	if resourceLimiter == nil {
		return &model.ResourceLimitsPayload{
			Success:        false,
			ResourceLimits: nil,
			Errors: []*model.MutationError{{
				Code:    "SERVICE_UNAVAILABLE",
				Message: "Resource limiter service is not available",
			}},
		}, nil
	}

	// Load the service instance from database
	instance, err := r.db.ServiceInstance.Query().
		Where(serviceinstance.IDEQ(input.InstanceID)).
		Where(serviceinstance.RouterIDEQ(input.RouterID)).
		Only(ctx)
	if err != nil {
		if ent.IsNotFound(err) {
			return &model.ResourceLimitsPayload{
				Success:        false,
				ResourceLimits: nil,
				Errors: []*model.MutationError{{
					Code:    "NOT_FOUND",
					Message: fmt.Sprintf("Service instance not found: %s", input.InstanceID),
				}},
			}, nil
		}
		r.log.Errorw("failed to query service instance",
			"error", err,
			"instanceID", input.InstanceID)
		return &model.ResourceLimitsPayload{
			Success:        false,
			ResourceLimits: nil,
			Errors: []*model.MutationError{{
				Code:    "DATABASE_ERROR",
				Message: fmt.Sprintf("Failed to query service instance: %v", err),
			}},
		}, nil
	}

	// Check if instance is running (would need PID to apply limits)
	// For MVP, we'll assume we can get the PID from the instance manager
	// In production, this would be stored in the database or tracked by InstanceManager
	pid := 0 // Placeholder - would come from instance manager's process tracker

	// Validate memory limit (minimum 16MB)
	if input.MemoryMb < 16 {
		return &model.ResourceLimitsPayload{
			Success:        false,
			ResourceLimits: nil,
			Errors: []*model.MutationError{{
				Code:    "INVALID_INPUT",
				Message: fmt.Sprintf("Memory limit %dMB is below minimum 16MB", input.MemoryMb),
				Field:   ptrString("memoryMB"),
			}},
		}, nil
	}

	// Apply memory limit via ResourceLimiter
	err = resourceLimiter.ApplyMemoryLimit(ctx, pid, input.MemoryMb, instance.ID, instance.FeatureID)
	if err != nil {
		r.log.Errorw("failed to apply memory limit",
			"error", err,
			"instanceID", input.InstanceID,
			"memoryMB", input.MemoryMb)
		return &model.ResourceLimitsPayload{
			Success:        false,
			ResourceLimits: nil,
			Errors: []*model.MutationError{{
				Code:    "LIMIT_APPLICATION_FAILED",
				Message: fmt.Sprintf("Failed to apply memory limit: %v", err),
			}},
		}, nil
	}

	// Return success with updated resource limits
	resourceLimits := &model.ResourceLimits{
		MemoryMb:   input.MemoryMb,
		CPUPercent: nil,
		Applied:    resourceLimiter.IsCgroupsEnabled(),
	}

	r.log.Infow("resource limits applied successfully",
		"instanceID", input.InstanceID,
		"memoryMB", input.MemoryMb,
		"cgroupsEnabled", resourceLimits.Applied)

	return &model.ResourceLimitsPayload{
		Success:        true,
		ResourceLimits: resourceLimits,
		Errors:         []*model.MutationError{},
	}, nil
}
*/
